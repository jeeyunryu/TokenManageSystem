{
  "manifest": {
    "name": "streaming-iterables",
    "version": "6.2.0",
    "description": "A collection of utilities for async iterables. Designed to replace your streams.",
    "main": "./dist/index.js",
    "module": "./dist/index.mjs",
    "exports": {
      "require": "./dist/index.js",
      "import": "./dist/index.mjs"
    },
    "types": "dist/index.d.ts",
    "repository": {
      "type": "git",
      "url": "git@github.com:reconbot/streaming-iterables.git"
    },
    "homepage": "https://github.com/reconbot/streaming-iterables",
    "runkitExampleFilename": "example.js",
    "scripts": {
      "test": "npm run unit-test && npm run lint",
      "unit-test": "c8 -r html -r text mocha",
      "check-coverage": "c8 check-coverage --lines 95 --functions 95 --branches 94",
      "lint": "tsc && tslint lib/*.ts",
      "format": "tslint lib/*.ts --fix",
      "build": "tsc -p tsconfig-build.json && rollup -c && api-extractor run --local --verbose",
      "prepare": "npm run build"
    },
    "keywords": [
      "async",
      "generators",
      "async generators",
      "async iterables",
      "iterators",
      "async iterators",
      "promise",
      "stream",
      "fp",
      "transform",
      "generator functions",
      "async generator functions",
      "bluestream",
      "ramda"
    ],
    "author": {
      "name": "reconbot"
    },
    "license": "MIT",
    "devDependencies": {
      "@microsoft/api-extractor": "^7.8.15",
      "@types/chai": "^4.2.11",
      "@types/mocha": "^9.1.0",
      "@types/node": "^17.0.14",
      "@types/sinon": "^10.0.10",
      "benchmark": "^2.1.4",
      "bluestream": "^10.3.3",
      "c8": "^7.11.0",
      "chai": "^4.3.6",
      "mocha": "^9.2.0",
      "prettier": "^2.5.1",
      "rollup": "^2.67.0",
      "rollup-plugin-node-resolve": "^5.2.0",
      "sinon": "^13.0.1",
      "through2-concurrent": "^2.0.0",
      "ts-node": "^10.4.0",
      "tslib": "^2.0.0",
      "tslint": "^6.1.2",
      "tslint-config-prettier": "^1.18.0",
      "tslint-plugin-prettier": "^2.3.0",
      "typescript": "^4.5.5"
    },
    "engines": {
      "node": ">=10"
    },
    "mocha": {
      "bail": true,
      "require": [
        "ts-node/register"
      ],
      "spec": "lib/*-test.ts"
    },
    "_registry": "npm",
    "_loc": "/home/ubuntu/.cache/yarn/v6/npm-streaming-iterables-6.2.0-e8079bc56272335b287e2f13274602fbef008e56-integrity/node_modules/streaming-iterables/package.json",
    "readmeFilename": "README.md",
    "readme": "# streaming-iterables üèÑ‚Äç‚ôÇÔ∏è\n\n[![Node CI](https://github.com/reconbot/streaming-iterables/workflows/Node%20CI/badge.svg?branch=master)](https://github.com/reconbot/streaming-iterables/actions?query=workflow%3A%22Node+CI%22) [![Try streaming-iterables on RunKit](https://badge.runkitcdn.com/streaming-iterables.svg)](https://npm.runkit.com/streaming-iterables) [![install size](https://packagephobia.now.sh/badge?p=streaming-iterables)](https://packagephobia.now.sh/result?p=streaming-iterables)\n\nA Swiss army knife for [async iterables](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of). Designed to help replace your streams. These utilities have a comparable speed, friendlier error handling, and are easier to understand than most stream based workloads.\n\nStreams were our last best hope for processing unbounded amounts of data. Since Node 10 they have become something greater, they've become async iterable. With async iterators you can have less code, do more work, faster.\n\nIf you still need streams with async functions, check out sister project [`bluestream`üèÑ‚Äç‚ôÄÔ∏è](https://www.npmjs.com/package/bluestream)!\n\nWe support and test against LTS node releases, but may work with older versions of node.\n\n## Install\nThere are no dependencies.\n\n```bash\nnpm install streaming-iterables\n```\n\nWe ship esm, umd and types.\n\n## Overview\nEvery function is curryable, you can call it with any number of arguments. For example:\n\n```ts\nimport { map } from 'streaming-iterables'\n\nfor await (const str of map(String, [1,2,3])) {\n  console.log(str)\n}\n// \"1\", \"2\", \"3\"\n\nconst stringable = map(String)\nfor await (const str of stringable([1,2,3])) {\n  console.log(str)\n}\n// \"1\", \"2\", \"3\"\n```\n\nSince this works with async iterators it requires node 10 or higher.\n\n## API\n\n- [`batch()`](#batch)\n- [`batchWithTimeout()`](#batchwithtimeout)\n- [`buffer()`](#buffer)\n- [`collect()`](#collect)\n- [`concat()`](#concat)\n- [`consume()`](#consume)\n- [`flatMap()`](#flatmap)\n- [`flatten()`](#flatten)\n- [`flatTransform()`](#flattransform)\n- [`fromStream()`](#fromstream)\n- [`filter()`](#filter)\n- [`getIterator()`](#getiterator)\n- [`map()`](#map)\n- [`merge()`](#merge)\n- [`parallelMap()`](#parallelmap)\n- [`parallelMerge()`](#parallelmerge)\n- [`pipeline()`](#pipeline)\n- [`reduce()`](#reduce)\n- [`take()`](#take)\n- [`tap()`](#tap)\n- [`throttle()`](#throttle)\n- [`time()`](#time)\n- [`transform()`](#transform)\n- [`writeToStream()`](#writetostream)\n\n### batch\n```ts\nfunction batch<T>(size: number, iterable: AsyncIterable<T>): AsyncGenerator<T[]>\nfunction batch<T>(size: number, iterable: Iterable<T>): Generator<T[]>\n```\n\nBatch objects from `iterable` into arrays of `size` length. The final array may be shorter than size if there is not enough items. Returns a sync iterator if the `iterable` is sync, otherwise an async iterator. Errors from the source `iterable` are immediately raised.\n\n`size` can be between 1 and `Infinity`.\n\n```ts\nimport { batch } from 'streaming-iterables'\nimport { getPokemon } from 'iterable-pokedex'\n\n// batch 10 pokemon while we process them\nfor await (const pokemons of batch(10, getPokemon())) {\n  console.log(pokemons) // 10 pokemon at a time!\n}\n```\n\n### batchWithTimeout\n```ts\nfunction batchWithTimeout<T>(size: number, timeout: number, iterable: AsyncIterable<T>): AsyncGenerator<T[]>\nfunction batchWithTimeout<T>(size: number, timeout: number, iterable: Iterable<T>): Generator<T[]>\n```\n\nLike [`batch`](#batch) but flushes early if the `timeout` is reached. The batches may be shorter than size if there are not enough items. Returns a sync iterator if the `iterable` is sync, otherwise an async iterator. Errors from the source `iterable` are immediately raised.\n\n`size` can be between 1 and `Infinity`.\n`timeout` can be between 0 and `Infinity`.\n\n```ts\nimport { batchWithTimeout } from 'streaming-iterables'\nimport { getPokemon } from 'iterable-pokedex'\n\n// batch 10 pokemon while we process them\nfor await (const pokemons of batchWithTimeout(10, 100, getPokemon())) {\n  console.log(pokemons) // Up to 10 pokemon at a time!\n}\n```\n\n### buffer\n```ts\nfunction buffer<T>(size: number, iterable: AsyncIterable<T>): AsyncIterable<T>\nfunction buffer<T>(size: number, iterable: Iterable<T>): AsyncIterable<T>\n```\nBuffer keeps a number of objects in reserve available for immediate reading. This is helpful with async iterators as it will pre-fetch results so you don't have to wait for them to load. For sync iterables it will pre-compute up to `size` values and keep them in reserve. The internal buffer will start to be filled once `.next()` is called for the first time and will continue to fill until the source `iterable` is exhausted or the buffer is full. Errors from the source `iterable` will be raised after all buffered values are yielded.\n\n`size` can be between 0 and `Infinity`.\n\n```ts\nimport { buffer } from 'streaming-iterables'\nimport { getPokemon, trainMonster } from 'iterable-pokedex'\n\n// load 10 monsters in the background while we process them one by one\nfor await (const monster of buffer(10, getPokemon())) {\n  await trainMonster(monster) // got to do some pok√©work\n}\n```\n\n### collect\n```ts\nfunction collect<T>(iterable: Iterable<T>): T[]\nfunction collect<T>(iterable: AsyncIterable<T>): Promise<T[]>\n```\n\nCollect all the values from an iterable into an array. Returns an array if you pass it an iterable and a promise for an array if you pass it an async iterable. Errors from the source `iterable` are raised immediately.\n\n```ts\nimport { collect } from 'streaming-iterables'\nimport { getPokemon } from 'iterable-pokedex'\n\nconsole.log(await collect(getPokemon()))\n// [bulbasaur, ivysaur, venusaur, charmander, ...]\n```\n\n### concat\n```ts\nfunction concat(...iterables: Array<Iterable<any>>): Iterable<any>\nfunction concat(...iterables: Array<AnyIterable<any>>): AsyncIterable<any>\n```\n\nCombine multiple iterators into a single iterable. Reads each iterable completely one at a time. Returns a sync iterator if all `iterables` are sync, otherwise it returns an async iterable. Errors from the source `iterable` are raised immediately.\n\n```ts\nimport { concat } from 'streaming-iterables'\nimport { getPokemon } from 'iterable-pokedex'\nimport { getTransformers } from './util'\n\nfor await (const hero of concat(getPokemon(2), getTransformers(2))) {\n  console.log(hero)\n}\n// charmander\n// bulbasaur <- end of pokemon\n// megatron\n// bumblebee <- end of transformers\n```\n\n### consume\n```ts\nexport function consume<T>(iterable: Iterable<T>): void\nexport function consume<T>(iterable: AsyncIterable<T>): Promise<void>\n```\n\nA promise that resolves after the function drains the iterable of all data. Useful for processing a pipeline of data. Errors from the source `iterable` are raised immediately.\n\n```ts\nimport { consume, map } from 'streaming-iterables'\nimport { getPokemon, trainMonster } from 'iterable-pokedex'\n\nconst train = map(trainMonster)\nawait consume(train(getPokemon())) // load all the pokemon and train them!\n```\n\n### flatMap\n```ts\nfunction flatMap<T, B>(func: (data: T) => FlatMapValue<B>, iterable: AnyIterable<T>): AsyncGenerator<B>\n```\n\nMap `func` over the `iterable`, flatten the result and then ignore all null or undefined values. It's the transform function we've always needed. It's equivalent to;\n```ts\n(func, iterable) => filter(i => i !== undefined && i !== null, flatten(map(func, iterable)))\n```\n\n*note*: The return value for `func` is `FlatMapValue<B>`. Typescript doesn't have recursive types but you can nest iterables as deep as you like.\n\nThe ordering of the results is guaranteed. Errors from the source `iterable` are raised after all mapped values are yielded. Errors from `func` are raised after all previously mapped values are yielded.\n\n```ts\nimport { flatMap } from 'streaming-iterables'\nimport { getPokemon, lookupStats } from 'iterable-pokedex'\n\nasync function getDefeatedGyms(pokemon) {\n  if (pokemon.gymBattlesWon > 0) {\n    const stats = await lookupStats(pokemon)\n    return stats.gyms\n  }\n}\n\nfor await (const gym of flatMap(getDefeatedGyms, getPokemon())) {\n  console.log(gym.name)\n}\n// \"Pewter Gym\"\n// \"Cerulean Gym\"\n// \"Vermilion Gym\"\n```\n\n### flatten\n```ts\nfunction flatten<B>(iterable: AnyIterable<B | AnyIterable<B>>): AsyncIterableIterator<B>\n```\n\nReturns a new iterator by pulling every item out of `iterable` (and all its sub iterables) and yielding them depth-first. Checks for the iterable interfaces and iterates it if it exists. If the value is a string it is not iterated as that ends up in an infinite loop. Errors from the source `iterable` are raised immediately.\n\n*note*: Typescript doesn't have recursive types but you can nest iterables as deep as you like.\n\n```ts\nimport { flatten } from 'streaming-iterables'\n\nfor await (const item of flatten([1, 2, [3, [4, 5], 6])) {\n  console.log(item)\n}\n// 1\n// 2\n// 3\n// 4\n// 5\n// 6\n```\n\n### flatTransform\n```ts\nfunction flatTransform<T, R>(concurrency: number, func: (data: T) => FlatMapValue<R>, iterable: AnyIterable<T>): AsyncIterableIterator<R>\n```\n\nMap `func` over the `iterable`, flatten the result and then ignore all null or undefined values. Returned async iterables are flattened concurrently too. It's the transform function we've always wanted.\n\nIt's similar to;\n```ts\nconst filterEmpty = filter(i => i !== undefined && i !== null)\n(concurrency, func, iterable) => filterEmpty(flatten(transform(concurrency, func, iterable)))\n```\n\n\n*note*: The return value for `func` is `FlatMapValue<B>`. Typescript doesn't have recursive types but you can nest iterables as deep as you like. However only directly returned async iterables are processed concurrently. (Eg, if you use an async generator function as `func` it's output will be processed concurrently, but if it's nested inside other iterables it will be processed sequentially.)\n\nOrder is determined by when async operations resolve. And it will run up to `concurrency` async operations at once. This includes promises and async iterables returned from `func`. Errors from the source `iterable` are raised after all transformed values are yielded. Errors from `func` are raised after all previously transformed values are yielded.\n\n`concurrency` can be between 1 and `Infinity`.\n\nPromise Example;\n```ts\nimport { flatTransform } from 'streaming-iterables'\nimport { getPokemon, lookupStats } from 'iterable-pokedex'\n\nasync function getDefeatedGyms(pokemon) {\n  if (pokemon.gymBattlesWon > 0) {\n    const stats = await lookupStats(pokemon)\n    return stats.gyms\n  }\n}\n\n// lookup 10 stats at a time\nfor await (const gym of flatTransform(10, getDefeatedGyms, getPokemon())) {\n  console.log(gym.name)\n}\n// \"Pewter Gym\"\n// \"Cerulean Gym\"\n// \"Vermilion Gym\"\n```\n\nAsync Generator Example\n```ts\nimport { flatTransform } from 'streaming-iterables'\nimport { getPokemon } from 'iterable-pokedex'\nimport { findFriendsFB, findFriendsMySpace } from './util'\n\n\nasync function* findFriends (pokemon) {\n  yield await findFriendsFB(pokemon.name)\n  yield await findFriendsMySpace(pokemon.name)\n}\n\nfor await (const pokemon of flatTransform(10, findFriends, getPokemon())) {\n  console.log(pokemon.name)\n}\n// Pikachu\n// Meowth\n// Ash - FB\n// Jessie - FB\n// Misty - MySpace\n// James - MySpace\n```\n\n### fromStream\n```ts\nfunction fromStream<T>(stream: Readable): AsyncIterable<T>\n```\n\nWraps the stream in an async iterator or returns the stream if it already is an async iterator.\n\n*note*: Since Node 10, streams already async iterators. This function may be used to ensure compatibility with older versions of Node.\n\n```ts\nimport { fromStream } from 'streaming-iterables'\nimport { createReadStream } from 'fs'\n\nconst pokeLog = fromStream(createReadStream('./pokedex-operating-system.log'))\n\nfor await (const pokeData of pokeLog) {\n  console.log(pokeData) // Buffer(...)\n}\n```\n\n### filter\n```ts\nfunction filter<T>(filterFunc: (data: T) => boolean | Promise<boolean>, iterable: AnyIterable<T>): AsyncIterableIterator<T>\n```\n\nTakes a `filterFunc` and a `iterable`, and returns a new async iterator of the same type containing the members of the given iterable which cause the `filterFunc` to return true.\n\n```ts\nimport { filter } from 'streaming-iterables'\nimport { getPokemon } from 'iterable-pokedex'\n\nconst filterWater = filter(pokemon => pokemon.types.include('Water'))\n\nfor await (const pokemon of filterWater(getPokemon())) {\n  console.log(pokemon)\n}\n// squirtle\n// vaporeon\n// magikarp\n```\n\n### getIterator\n```ts\nfunction getIterator<T>(values: Iterableish<T>): Iterator<T> | AsyncIterator<T>\n```\n\nGet the iterator from any iterable or just return an iterator itself.\n\n### map\n```ts\nfunction map<T, B>(func: (data: T) => B | Promise<B>, iterable: AnyIterable<T>): AsyncIterableIterator<B>\n```\nMap a function or async function over all the values of an iterable. Errors from the source `iterable` and `func` are raised immediately.\n\n```ts\nimport { consume, map } from 'streaming-iterables'\nimport got from 'got'\n\nconst urls = ['https://http.cat/200', 'https://http.cat/201', 'https://http.cat/202']\nconst download = map(got)\n\n// download one at a time\nfor await (page of download(urls)) {\n  console.log(page)\n}\n```\n\n### merge\n```ts\nfunction merge(...iterables: Array<AnyIterable<any>>): AsyncIterableIterator<any>\n```\n\nCombine multiple iterators into a single iterable. Reads one item off each iterable in order repeatedly until they are all exhausted. If you care less about order and want them faster see [`parallelMerge()`](#parallelmerge).\n\n### parallelMap\n```ts\nfunction parallelMap<T, R>(concurrency: number, func: (data: T) => R | Promise<R>, iterable: AnyIterable<T>): AsyncIterableIterator<R>\n```\n\nMap a function or async function over all the values of an iterable and do them concurrently. Errors from the source `iterable` are raised after all mapped values are yielded. Errors from `func` are raised after all previously mapped values are yielded. Just like [`map()`](#map).\n\n`concurrency` can be between 1 and `Infinity`.\n\nIf you don't care about order, see the faster [`transform()`](#transform) function.\n\n```ts\nimport { consume, parallelMap } from 'streaming-iterables'\nimport got from 'got'\n\nconst urls = ['https://http.cat/200', 'https://http.cat/201', 'https://http.cat/202']\nconst download = parallelMap(2, got)\n\n// download two at a time\nfor await (page of download(urls)) {\n  console.log(page)\n}\n```\n\n### parallelMerge\n```ts\nfunction parallelMerge<T>(...iterables: Array<AnyIterable<T>>): AsyncIterableIterator<T>\n```\nCombine multiple iterators into a single iterable. Reads one item off of every iterable and yields them as they resolve. This is useful for pulling items out of a collection of iterables as soon as they're available. Errors `iterables` are raised immediately.\n\n```ts\nimport { parallelMerge } from 'streaming-iterables'\nimport { getPokemon, getTransformer } from 'iterable-pokedex'\n\n// pokemon are much faster to load btw\nconst heros = parallelMerge(getPokemon(), getTransformer())\nfor await (const hero of heros) {\n  console.log(hero)\n}\n// charmander\n// bulbasaur\n// megatron\n// pikachu\n// eevee\n// bumblebee\n// jazz\n```\n\n### pipeline\n```ts\nfunction pipeline(firstFn: Function, ...fns: Function[]): any;\n```\n\nCalls `firstFn` and then every function in `fns` with the result of the previous function. The final return is the result of the last function in `fns`.\n\n```ts\nimport { pipeline, map, collect } from 'streaming-iterables'\nimport { getPokemon } from 'iterable-pokedex'\nconst getName = map(pokemon => pokemon.name)\n\n// equivalent to `await collect(getName(getPokemon()))`\nawait pipeline(getPokemon, getName, collect)\n// charmander\n// bulbasaur\n// MissingNo.\n```\n\n### reduce\n```ts\nfunction reduce<T, B>(func: (acc: B, value: T) => B, start: B, iterable: AnyIterable<T>): Promise<B>\n```\n\nAn async function that takes a reducer function, an initial value and an iterable.\n\nReduces an iterable to a value which is the accumulated result of running each value from the iterable thru `func`, where each successive invocation is supplied the return value of the previous. Errors are immediate raised.\n\n### take\n```ts\nfunction take<T>(count: number, iterable: AsyncIterable<T>): AsyncIterableIterator<T>\nfunction take<T>(count: number, iterable: Iterable<T>): IterableIterator<T>\n```\nReturns a new iterator that reads a specific number of items from `iterable`. When used with generators it advances the generator, when used with arrays it gets a new iterator and starts from the beginning.\n\n### tap\n```ts\nfunction tap<T>(func: (data: T) => any, iterable: AnyIterable<T>): AsyncIterableIterator<T>\n```\n\nReturns a new iterator that yields the data it consumes, passing the data through to a function. If you provide an async function, the iterator will wait for the promise to resolve before yielding the value. This is useful for logging, or processing information and passing it along.\n\n### throttle\n```ts\nfunction throttle<T>(limit: number, interval: number, iterable: AnyIterable<T>): AsyncGenerator<T>\n```\n\nThrottles `iterable` at a rate of `limit` per `interval` without discarding data. Useful for throttling rate limited APIs.\n\n`limit` can be greater than 0 but less than `Infinity`.\n`interval` can be greater than or equal to 0 but less than `Infinity`.\n\n```ts\nimport { throttle } from 'streaming-iterables'\nimport { getPokemon, trainMonster } from 'iterable-pokedex'\n\n// load monsters at a maximum rate of 1 per second\nfor await (const monster of throttle(1, 1000, getPokemon())) {\n  await trainMonster(monster)\n}\n```\n\n### time\n```ts\nfunction time<T>(config?: ITimeConfig, iterable: AsyncIterable<R>): AsyncIterableIterator<R>\nfunction time<T>(config?: ITimeConfig, iterable: Iterable<R>): IterableIterator<R>\n\ninterface ITimeConfig {\n    progress?: (delta: [number, number], total: [number, number]) => any;\n    total?: (time: [number, number]) => any;\n}\n```\nReturns a new iterator that yields the data it consumes and calls the `progress` and `total` callbacks with the [`hrtime`](https://nodejs.org/api/process.html#process_process_hrtime_time) it took for `iterable` to provide a value when `.next()` was called on it. That is to say, the time returned is the time this iterator spent waiting for data, not the time it took to finish being read. The `hrtime` tuple looks like `[seconds, nanoseconds]`.\n\n\n```ts\nimport { consume, transform, time } from 'streaming-iterables'\nimport got from 'got'\n\nconst urls = ['https://http.cat/200', 'https://http.cat/201', 'https://http.cat/202']\nconst download = transform(1000, got)\nconst timer = time({\n  total: total => console.log(`Spent ${total[0]} seconds and ${total[1]}ns downloading cats`),\n})\n// download all of these at the same time\nfor await (page of timer(download(urls))) {\n  console.log(page)\n}\n\n```\n### transform\n```ts\nfunction transform<T, R>(concurrency: number, func: (data: T) => R | Promise<R>, iterable: AnyIterable<T>): AsyncIterableIterator<R>\n```\nMap a function or async function over all the values of an iterable. Order is determined by when `func` resolves. And it will run up to `concurrency` async `func` operations at once. If you care about order see [`parallelMap()`](#parallelmap). Errors from the source `iterable` are raised after all transformed values are yielded. Errors from `func` are raised after all previously transformed values are yielded.\n\n`concurrency` can be between 1 and `Infinity`.\n\n```ts\nimport { consume, transform } from 'streaming-iterables'\nimport got from 'got'\n\nconst urls = ['https://http.cat/200', 'https://http.cat/201', 'https://http.cat/202']\nconst download = transform(1000, got)\n\n// download all of these at the same time\nfor await (page of download(urls)) {\n  console.log(page)\n}\n```\n\n### writeToStream\n```ts\nfunction writeToStream(stream: Writable, iterable: AnyIterable<any>): Promise<void>\n```\n\nWrites the `iterable` to the stream respecting the stream back pressure. Resolves when the iterable is exhausted, rejects if the stream errors during calls to `write()` or if there are `error` events during the write.\n\nAs it is when working with streams there are a few caveats;\n- It is possible for the stream to error after `writeToStream()` has finished writing due to internal buffering and other concerns, so always handle errors on the stream as well.\n- `writeToStream()` doesn't close the stream like `stream.pipe()` might. This is done so you can write to the stream multiple times. You can call `stream.write(null)` or any stream specific end function if you are done with the stream.\n\n```ts\nimport { pipeline, map, writeToStream } from 'streaming-iterables'\nimport { getPokemon } from 'iterable-pokedex'\nimport { createWriteStream } from 'fs'\n\nconst file = createWriteStream('pokemon.ndjson')\nconst serialize = map(pokemon => `${JSON.stringify(pokemon)}\\n`)\nawait pipeline(getPokemon, serialize, writeToStream(file))\nfile.end() // close the stream\n// now all the pokemon are written to the file!\n```\n\n## Types\n\n### Iterableish\n```ts\ntype Iterableish<T> = Iterable<T> | Iterator<T> | AsyncIterable<T> | AsyncIterator<T>\n```\nAny iterable or iterator.\n\n### AnyIterable\n```ts\ntype AnyIterable<T> = Iterable<T> | AsyncIterable<T>\n```\nLiterally any `Iterable` (async or regular).\n\n### FlatMapValue\n```ts\ntype FlatMapValue<B> = B | AnyIterable<B> | undefined | null | Promise<B | AnyIterable<B> | undefined | null>\n```\nA value, an array of that value, undefined, null or promises for any of them. Used in the `flatMap` and `flatTransform` functions as possible return values of the mapping function.\n\n## Contributors wanted!\n\nWriting docs and code is a lot of work! Thank you in advance for helping out.\n",
    "licenseText": "MIT License\n\nCopyright (c) 2020 Francis Gulotta\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/streaming-iterables/-/streaming-iterables-6.2.0.tgz#e8079bc56272335b287e2f13274602fbef008e56",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/streaming-iterables/-/streaming-iterables-6.2.0.tgz",
    "hash": "e8079bc56272335b287e2f13274602fbef008e56",
    "integrity": "sha512-3AYC8oB60WyD1ic7uHmN/vm2oRGzRnQ3XFBl/bFMDi1q1+nc5/vjMmiE4vroIya3jG59t87VpyAj/iXYxyw9AA==",
    "registry": "npm",
    "packageName": "streaming-iterables",
    "cacheIntegrity": "sha512-3AYC8oB60WyD1ic7uHmN/vm2oRGzRnQ3XFBl/bFMDi1q1+nc5/vjMmiE4vroIya3jG59t87VpyAj/iXYxyw9AA== sha1-6AebxWJyM1sofi8TJ0YC++8AjlY="
  },
  "registry": "npm",
  "hash": "e8079bc56272335b287e2f13274602fbef008e56"
}