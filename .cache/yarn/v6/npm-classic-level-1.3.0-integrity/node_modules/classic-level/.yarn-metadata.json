{
  "manifest": {
    "name": "classic-level",
    "version": "1.3.0",
    "description": "An abstract-level database backed by LevelDB",
    "license": "MIT",
    "main": "index.js",
    "types": "./index.d.ts",
    "scripts": {
      "install": "node-gyp-build",
      "test": "standard && (nyc -s tape test/*-test.js | faucet) && nyc report",
      "test-gc": "node --expose-gc test/gc.js",
      "test-electron": "electron test/electron.js",
      "test-prebuild": "cross-env PREBUILDS_ONLY=1 npm t",
      "coverage": "nyc report -r lcovonly",
      "rebuild": "npm run install --build-from-source",
      "prebuild": "prebuildify -t 8.14.0 --napi --strip",
      "download-prebuilds": "prebuildify-ci download",
      "hallmark": "hallmark --fix",
      "dependency-check": "dependency-check --no-dev -i napi-macros . test/*.js",
      "prepublishOnly": "npm run dependency-check",
      "prebuild-linux-arm": "prebuildify-cross -i linux-armv6 -i linux-armv7 -i linux-arm64-lts -t 8.14.0 --napi --strip",
      "prebuild-android-arm": "prebuildify-cross -i android-armv7 -i android-arm64 -t 8.14.0 --napi --strip",
      "prebuild-linux-x64": "prebuildify-cross -i centos7-devtoolset7 -i alpine -t 8.14.0 --napi --strip",
      "prebuild-darwin-x64+arm64": "prebuildify -t 8.14.0 --napi --strip --arch x64+arm64",
      "prebuild-win32-x86": "prebuildify -t 8.14.0 --napi --strip",
      "prebuild-win32-x64": "prebuildify -t 8.14.0 --napi --strip"
    },
    "dependencies": {
      "abstract-level": "^1.0.2",
      "catering": "^2.1.0",
      "module-error": "^1.0.1",
      "napi-macros": "^2.2.2",
      "node-gyp-build": "^4.3.0"
    },
    "devDependencies": {
      "@types/node": "^18.0.0",
      "@voxpelli/tsconfig": "^4.0.0",
      "async-each": "^1.0.3",
      "cross-env": "^7.0.3",
      "delayed": "^2.0.0",
      "dependency-check": "^4.1.0",
      "du": "^1.0.0",
      "electron": "^21.0.1",
      "faucet": "^0.0.3",
      "glob": "^8.0.1",
      "hallmark": "^4.1.0",
      "mkfiletree": "^2.0.0",
      "node-gyp": "^9.0.0",
      "nyc": "^15.0.0",
      "prebuildify": "^5.0.0",
      "prebuildify-ci": "^1.0.4",
      "prebuildify-cross": "^5.0.0",
      "readfiletree": "^1.0.0",
      "rimraf": "^3.0.0",
      "standard": "^17.0.0",
      "tape": "^5.5.0",
      "tempy": "^1.0.1",
      "typescript": "^4.5.5"
    },
    "gypfile": true,
    "repository": {
      "type": "git",
      "url": "https://github.com/Level/classic-level.git"
    },
    "homepage": "https://github.com/Level/classic-level",
    "keywords": [
      "leveldb",
      "level"
    ],
    "engines": {
      "node": ">=12"
    },
    "_registry": "npm",
    "_loc": "/home/ubuntu/.cache/yarn/v6/npm-classic-level-1.3.0-integrity/node_modules/classic-level/package.json",
    "readmeFilename": "README.md",
    "readme": "# classic-level\n\n**An [`abstract-level`](https://github.com/Level/abstract-level) database backed by [LevelDB](https://github.com/google/leveldb).** The successor to [`leveldown`](https://github.com/Level/leveldown) with builtin encodings, sublevels, events, promises and support of Uint8Array. If you are upgrading please see [`UPGRADING.md`](UPGRADING.md).\n\n> :pushpin: Which module should I use? What is `abstract-level`? Head over to the [FAQ](https://github.com/Level/community#faq).\n\n[![level badge][level-badge]](https://github.com/Level/awesome)\n[![npm](https://img.shields.io/npm/v/classic-level.svg)](https://www.npmjs.com/package/classic-level)\n[![Node version](https://img.shields.io/node/v/classic-level.svg)](https://www.npmjs.com/package/classic-level)\n[![Test](https://img.shields.io/github/workflow/status/Level/classic-level/Test?label=test)](https://github.com/Level/classic-level/actions/workflows/test.yml)\n[![Coverage](https://img.shields.io/codecov/c/github/Level/classic-level?label=\\&logo=codecov\\&logoColor=fff)](https://codecov.io/gh/Level/classic-level)\n[![Standard](https://img.shields.io/badge/standard-informational?logo=javascript\\&logoColor=fff)](https://standardjs.com)\n[![Common Changelog](https://common-changelog.org/badge.svg)](https://common-changelog.org)\n[![Donate](https://img.shields.io/badge/donate-orange?logo=open-collective\\&logoColor=fff)](https://opencollective.com/level)\n\n## Table of Contents\n\n<details><summary>Click to expand</summary>\n\n- [Usage](#usage)\n- [Supported Platforms](#supported-platforms)\n- [API](#api)\n  - [`db = new ClassicLevel(location[, options])`](#db--new-classiclevellocation-options)\n  - [`db.location`](#dblocation)\n  - [`db.status`](#dbstatus)\n  - [`db.open([options][, callback])`](#dbopenoptions-callback)\n  - [`db.close([callback])`](#dbclosecallback)\n  - [`db.supports`](#dbsupports)\n  - [`db.get(key[, options][, callback])`](#dbgetkey-options-callback)\n  - [`db.getMany(keys[, options][, callback])`](#dbgetmanykeys-options-callback)\n  - [`db.put(key, value[, options][, callback])`](#dbputkey-value-options-callback)\n  - [`db.del(key[, options][, callback])`](#dbdelkey-options-callback)\n  - [`db.batch(operations[, options][, callback])`](#dbbatchoperations-options-callback)\n  - [`chainedBatch = db.batch()`](#chainedbatch--dbbatch)\n  - [`iterator = db.iterator([options])`](#iterator--dbiteratoroptions)\n    - [About high water](#about-high-water)\n  - [`keyIterator = db.keys([options])`](#keyiterator--dbkeysoptions)\n  - [`valueIterator = db.values([options])`](#valueiterator--dbvaluesoptions)\n  - [`db.clear([options][, callback])`](#dbclearoptions-callback)\n  - [`sublevel = db.sublevel(name[, options])`](#sublevel--dbsublevelname-options)\n  - [`db.approximateSize(start, end[, options][, callback])`](#dbapproximatesizestart-end-options-callback)\n  - [`db.compactRange(start, end[, options][, callback])`](#dbcompactrangestart-end-options-callback)\n  - [`db.getProperty(property)`](#dbgetpropertyproperty)\n  - [`chainedBatch`](#chainedbatch)\n    - [`chainedBatch.put(key, value[, options])`](#chainedbatchputkey-value-options)\n    - [`chainedBatch.del(key[, options])`](#chainedbatchdelkey-options)\n    - [`chainedBatch.clear()`](#chainedbatchclear)\n    - [`chainedBatch.write([options][, callback])`](#chainedbatchwriteoptions-callback)\n    - [`chainedBatch.close([callback])`](#chainedbatchclosecallback)\n    - [`chainedBatch.length`](#chainedbatchlength)\n    - [`chainedBatch.db`](#chainedbatchdb)\n  - [`iterator`](#iterator)\n    - [`for await...of iterator`](#for-awaitof-iterator)\n    - [`iterator.next([callback])`](#iteratornextcallback)\n    - [`iterator.nextv(size[, options][, callback])`](#iteratornextvsize-options-callback)\n    - [`iterator.all([options][, callback])`](#iteratoralloptions-callback)\n    - [`iterator.seek(target[, options])`](#iteratorseektarget-options)\n    - [`iterator.close([callback])`](#iteratorclosecallback)\n    - [`iterator.db`](#iteratordb)\n    - [`iterator.count`](#iteratorcount)\n    - [`iterator.limit`](#iteratorlimit)\n  - [`keyIterator`](#keyiterator)\n  - [`valueIterator`](#valueiterator)\n  - [`sublevel`](#sublevel)\n    - [`sublevel.prefix`](#sublevelprefix)\n    - [`sublevel.db`](#subleveldb)\n  - [`ClassicLevel.destroy(location[, callback])`](#classicleveldestroylocation-callback)\n  - [`ClassicLevel.repair(location[, callback])`](#classiclevelrepairlocation-callback)\n- [Development](#development)\n  - [Getting Started](#getting-started)\n  - [Contributing](#contributing)\n  - [Publishing](#publishing)\n- [Donate](#donate)\n- [License](#license)\n\n</details>\n\n## Usage\n\n```js\nconst { ClassicLevel } = require('classic-level')\n\n// Create a database\nconst db = new ClassicLevel('./db', { valueEncoding: 'json' })\n\n// Add an entry with key 'a' and value 1\nawait db.put('a', 1)\n\n// Add multiple entries\nawait db.batch([{ type: 'put', key: 'b', value: 2 }])\n\n// Get value of key 'a': 1\nconst value = await db.get('a')\n\n// Iterate entries with keys that are greater than 'a'\nfor await (const [key, value] of db.iterator({ gt: 'a' })) {\n  console.log(value) // 2\n}\n```\n\nAll asynchronous methods also support callbacks.\n\n<details><summary>Callback example</summary>\n\n```js\ndb.put('example', { hello: 'world' }, (err) => {\n  if (err) throw err\n\n  db.get('example', (err, value) => {\n    if (err) throw err\n    console.log(value) // { hello: 'world' }\n  })\n})\n```\n\n</details>\n\nUsage from TypeScript requires generic type parameters.\n\n<details><summary>TypeScript example</summary>\n\n```ts\n// Specify types of keys and values (any, in the case of json).\n// The generic type parameters default to ClassicLevel<string, string>.\nconst db = new ClassicLevel<string, any>('./db', { valueEncoding: 'json' })\n\n// All relevant methods then use those types\nawait db.put('a', { x: 123 })\n\n// Specify different types when overriding encoding per operation\nawait db.get<string, string>('a', { valueEncoding: 'utf8' })\n\n// Though in some cases TypeScript can infer them\nawait db.get('a', { valueEncoding: db.valueEncoding('utf8') })\n\n// It works the same for sublevels\nconst abc = db.sublevel('abc')\nconst xyz = db.sublevel<string, any>('xyz', { valueEncoding: 'json' })\n```\n\n</details>\n\n## Supported Platforms\n\nWe aim to support _at least_ Active LTS and Current Node.js releases, Electron 5.0.0, as well as any future Node.js and Electron releases thanks to [Node-API](https://nodejs.org/api/n-api.html).\n\nThe `classic-level` npm package ships with prebuilt binaries for popular 64-bit platforms as well as ARM, M1, Android, Alpine (musl), Windows 32-bit, Linux flavors with an old glibc (Debian 8, Ubuntu 14.04, RHEL 7, CentOS 7) and is known to work on:\n\n- **Linux**, including ARM platforms such as Raspberry Pi and Kindle\n- **Mac OS** (10.7 and later)\n- **Windows**\n- **FreeBSD**\n\nWhen installing `classic-level`, [`node-gyp-build`](https://github.com/prebuild/node-gyp-build) will check if a compatible binary exists and fallback to compiling from source if it doesn't. In that case you'll need a [valid `node-gyp` installation](https://github.com/nodejs/node-gyp#installation).\n\nIf you don't want to use the prebuilt binary for the platform you are installing on, specify the `--build-from-source` flag when you install. One of:\n\n```\nnpm install --build-from-source\nnpm install classic-level --build-from-source\n```\n\nIf you are working on `classic-level` itself and want to recompile the C++ code, run `npm run rebuild`.\n\nNote: the Android prebuilds are made for and built against Node.js core rather than the [`nodejs-mobile`](https://github.com/JaneaSystems/nodejs-mobile) fork.\n\n## API\n\nThe API of `classic-level` follows that of [`abstract-level`](https://github.com/Level/abstract-level) with a few additional options and methods specific to LevelDB. The documentation below covers it all except for [Encodings](https://github.com/Level/abstract-level#encodings), [Events](https://github.com/Level/abstract-level#events) and [Errors](https://github.com/Level/abstract-level#errors) which are exclusively documented in `abstract-level`.\n\nAn `abstract-level` and thus `classic-level` database is at its core a [key-value database](https://en.wikipedia.org/wiki/Key%E2%80%93value_database). A key-value pair is referred to as an _entry_ here and typically returned as an array, comparable to [`Object.entries()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/entries).\n\n### `db = new ClassicLevel(location[, options])`\n\nCreate a database or open an existing database. The `location` argument must be a directory path (relative or absolute) where LevelDB will store its files. If the directory does not yet exist (and `options.createIfMissing` is true) it will be created recursively. The optional `options` object may contain:\n\n- `keyEncoding` (string or object, default `'utf8'`): encoding to use for keys\n- `valueEncoding` (string or object, default `'utf8'`): encoding to use for values.\n\nSee [Encodings](https://github.com/Level/abstract-level#encodings) for a full description of these options. Other `options` (except `passive`) are forwarded to `db.open()` which is automatically called in a next tick after the constructor returns. Any read & write operations are queued internally until the database has finished opening. If opening fails, those queued operations will yield errors.\n\n### `db.location`\n\nRead-only getter that returns the `location` string that was passed to the constructor (as-is).\n\n### `db.status`\n\nRead-only getter that returns a string reflecting the current state of the database:\n\n- `'opening'` - waiting for the database to be opened\n- `'open'` - successfully opened the database\n- `'closing'` - waiting for the database to be closed\n- `'closed'` - successfully closed the database.\n\n### `db.open([options][, callback])`\n\nOpen the database. The `callback` function will be called with no arguments when successfully opened, or with a single error argument if opening failed. The database has an exclusive lock (on disk): if another process or instance has already opened the underlying LevelDB store at the given `location` then opening will fail with error code [`LEVEL_LOCKED`](https://github.com/Level/abstract-level#errors). If no callback is provided, a promise is returned. Options passed to `open()` take precedence over options passed to the database constructor.\n\nThe optional `options` object may contain:\n\n- `createIfMissing` (boolean, default: `true`): If `true`, create an empty database if one doesn't already exist. If `false` and the database doesn't exist, opening will fail.\n- `errorIfExists` (boolean, default: `false`): If `true` and the database already exists, opening will fail.\n- `passive` (boolean, default: `false`): Wait for, but do not initiate, opening of the database.\n\nFor advanced performance tuning, the `options` object may also contain the following. Modify these options only if you can prove actual benefit for your particular application.\n\n<details>\n<summary>Click to expand</summary>\n\n- `compression` (boolean, default: `true`): Unless set to `false`, all _compressible_ data will be run through the Snappy compression algorithm before being stored. Snappy is very fast so leave this on unless you have good reason to turn it off.\n\n- `cacheSize` (number, default: `8 * 1024 * 1024`): The size (in bytes) of the in-memory [LRU](http://en.wikipedia.org/wiki/Least_Recently_Used) cache with frequently used uncompressed block contents.\n\n- `writeBufferSize` (number, default: `4 * 1024 * 1024`): The maximum size (in bytes) of the log (in memory and stored in the `.log` file on disk). Beyond this size, LevelDB will convert the log data to the first level of sorted table files. From LevelDB documentation:\n\n  > Larger values increase performance, especially during bulk loads. Up to two write buffers may be held in memory at the same time, so you may wish to adjust this parameter to control memory usage. Also, a larger write buffer will result in a longer recovery time the next time the database is opened.\n\n- `blockSize` (number, default: `4096`): The _approximate_ size of the blocks that make up the table files. The size relates to uncompressed data (hence \"approximate\"). Blocks are indexed in the table file and entry-lookups involve reading an entire block and parsing to discover the required entry.\n\n- `maxOpenFiles` (number, default: `1000`): The maximum number of files that LevelDB is allowed to have open at a time. If your database is likely to have a large working set, you may increase this value to prevent file descriptor churn. To calculate the number of files required for your working set, divide your total data size by `maxFileSize`.\n\n- `blockRestartInterval` (number, default: `16`): The number of entries before restarting the \"delta encoding\" of keys within blocks. Each \"restart\" point stores the full key for the entry, between restarts, the common prefix of the keys for those entries is omitted. Restarts are similar to the concept of keyframes in video encoding and are used to minimise the amount of space required to store keys. This is particularly helpful when using deep namespacing / prefixing in your keys.\n\n- `maxFileSize` (number, default: `2 * 1024 * 1024`): The maximum amount of bytes to write to a file before switching to a new one. From LevelDB documentation:\n\n  > If your filesystem is more efficient with larger files, you could consider increasing the value. The downside will be longer compactions and hence longer latency / performance hiccups. Another reason to increase this parameter might be when you are initially populating a large database.\n\n</details>\n\nIt's generally not necessary to call `open()` because it's automatically called by the database constructor. It may however be useful to capture an error from failure to open, that would otherwise not surface until another method like `db.get()` is called. It's also possible to reopen the database after it has been closed with [`close()`](#dbclosecallback). Once `open()` has then been called, any read & write operations will again be queued internally until opening has finished.\n\nThe `open()` and `close()` methods are idempotent. If the database is already open, the `callback` will be called in a next tick. If opening is already in progress, the `callback` will be called when that has finished. If closing is in progress, the database will be reopened once closing has finished. Likewise, if `close()` is called after `open()`, the database will be closed once opening has finished and the prior `open()` call will receive an error.\n\n### `db.close([callback])`\n\nClose the database. The `callback` function will be called with no arguments if closing succeeded or with a single `error` argument if closing failed. If no callback is provided, a promise is returned.\n\nA database has associated resources like file handles and locks. When the database is no longer needed (for the remainder of a program) it's recommended to call `db.close()` to free up resources. The underlying LevelDB store cannot be opened by multiple `classic-level` instances or processes simultaneously.\n\nAfter `db.close()` has been called, no further read & write operations are allowed unless and until `db.open()` is called again. For example, `db.get(key)` will yield an error with code [`LEVEL_DATABASE_NOT_OPEN`](https://github.com/Level/abstract-level#errors). Any unclosed iterators or chained batches will be closed by `db.close()` and can then no longer be used even when `db.open()` is called again.\n\nA `classic-level` database waits for any pending operations to finish before closing. For example:\n\n```js\ndb.put('key', 'value', function (err) {\n  // This happens first\n})\n\ndb.close(function (err) {\n  // This happens second\n})\n```\n\n### `db.supports`\n\nA [manifest](https://github.com/Level/supports) describing the features supported by this database. Might be used like so:\n\n```js\nif (!db.supports.permanence) {\n  throw new Error('Persistent storage is required')\n}\n```\n\n### `db.get(key[, options][, callback])`\n\nGet a value from the database by `key`. The optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding for this operation, used to encode the `key`.\n- `valueEncoding`: custom value encoding for this operation, used to decode the value.\n- `fillCache` (boolean, default: `true`): Unless set to `false`, LevelDB will fill its in-memory [LRU](http://en.wikipedia.org/wiki/Least_Recently_Used) cache with data that was read.\n\nThe `callback` function will be called with an error if the operation failed. If the key was not found, the error will have code [`LEVEL_NOT_FOUND`](https://github.com/Level/abstract-level#errors). If successful the first argument will be `null` and the second argument will be the value. If no callback is provided, a promise is returned.\n\nA `classic-level` database supports snapshots (as indicated by `db.supports.snapshots`) which means `db.get()` _should_ read from a snapshot of the database, created at the time `db.get()` was called. This means it should not see the data of simultaneous write operations. However, there's currently a small delay before the snapshot is created.\n\n### `db.getMany(keys[, options][, callback])`\n\nGet multiple values from the database by an array of `keys`. The optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding for this operation, used to encode the `keys`.\n- `valueEncoding`: custom value encoding for this operation, used to decode values.\n- `fillCache`: same as described for [`db.get()`](#dbgetkey-options-callback).\n\nThe `callback` function will be called with an error if the operation failed. If successful the first argument will be `null` and the second argument will be an array of values with the same order as `keys`. If a key was not found, the relevant value will be `undefined`. If no callback is provided, a promise is returned.\n\nA `classic-level` database supports snapshots (as indicated by `db.supports.snapshots`) which means `db.getMany()` _should_ read from a snapshot of the database, created at the time `db.getMany()` was called. This means it should not see the data of simultaneous write operations. However, there's currently a small delay before the snapshot is created.\n\n### `db.put(key, value[, options][, callback])`\n\nAdd a new entry or overwrite an existing entry. The optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding for this operation, used to encode the `key`.\n- `valueEncoding`: custom value encoding for this operation, used to encode the `value`.\n- `sync` (boolean, default: `false`): if set to `true`, LevelDB will perform a synchronous write of the data although the operation will be asynchronous as far as Node.js or Electron is concerned. Normally, LevelDB passes the data to the operating system for writing and returns immediately. In contrast, a synchronous write will use [`fsync()`](https://man7.org/linux/man-pages/man2/fsync.2.html) or equivalent, so the `put()` call will not complete until the data is actually on disk. Synchronous writes are significantly slower than asynchronous writes.\n\nThe `callback` function will be called with no arguments if the operation was successful or with an error if it failed. If no callback is provided, a promise is returned.\n\n### `db.del(key[, options][, callback])`\n\nDelete an entry by `key`. The optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding for this operation, used to encode the `key`.\n- `sync` (boolean, default: `false`): same as described for [`db.put()`](#dbputkey-value-options-callback)\n\nThe `callback` function will be called with no arguments if the operation was successful or with an error if it failed. If no callback is provided, a promise is returned.\n\n### `db.batch(operations[, options][, callback])`\n\nPerform multiple _put_ and/or _del_ operations in bulk. The `operations` argument must be an array containing a list of operations to be executed sequentially, although as a whole they are performed as an atomic operation.\n\nEach operation must be an object with at least a `type` property set to either `'put'` or `'del'`. If the `type` is `'put'`, the operation must have `key` and `value` properties. It may optionally have `keyEncoding` and / or `valueEncoding` properties to encode keys or values with a custom encoding for just that operation. If the `type` is `'del'`, the operation must have a `key` property and may optionally have a `keyEncoding` property.\n\nAn operation of either type may also have a `sublevel` property, to prefix the key of the operation with the prefix of that sublevel. This allows atomically committing data to multiple sublevels. Keys and values will be encoded by the sublevel, to the same effect as a `sublevel.batch(..)` call. In the following example, the first `value` will be encoded with `'json'` rather than the default encoding of `db`:\n\n```js\nconst people = db.sublevel('people', { valueEncoding: 'json' })\nconst nameIndex = db.sublevel('names')\n\nawait db.batch([{\n  type: 'put',\n  sublevel: people,\n  key: '123',\n  value: {\n    name: 'Alice'\n  }\n}, {\n  type: 'put',\n  sublevel: nameIndex,\n  key: 'Alice',\n  value: '123'\n}])\n```\n\nThe optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding for this batch, used to encode keys.\n- `valueEncoding`: custom value encoding for this batch, used to encode values.\n- `sync` (boolean, default: `false`): same as described for [`db.put()`](#dbputkey-value-options-callback).\n\nEncoding properties on individual operations take precedence. In the following example, the first value will be encoded with the `'utf8'` encoding and the second with `'json'`.\n\n```js\nawait db.batch([\n  { type: 'put', key: 'a', value: 'foo' },\n  { type: 'put', key: 'b', value: 123, valueEncoding: 'json' }\n], { valueEncoding: 'utf8' })\n```\n\nThe `callback` function will be called with no arguments if the batch was successful or with an error if it failed. If no callback is provided, a promise is returned.\n\n### `chainedBatch = db.batch()`\n\nCreate a [`chained batch`](#chainedbatch), when `batch()` is called with zero arguments. A chained batch can be used to build and eventually commit an atomic batch of operations. Depending on how it's used, it is possible to obtain greater performance with this form of `batch()`.\n\n```js\nawait db.batch()\n  .del('bob')\n  .put('alice', 361)\n  .put('kim', 220)\n  .write()\n```\n\n### `iterator = db.iterator([options])`\n\nCreate an [`iterator`](#iterator). The optional `options` object may contain the following _range options_ to control the range of entries to be iterated:\n\n- `gt` (greater than) or `gte` (greater than or equal): define the lower bound of the range to be iterated. Only entries where the key is greater than (or equal to) this option will be included in the range. When `reverse` is true the order will be reversed, but the entries iterated will be the same.\n- `lt` (less than) or `lte` (less than or equal): define the higher bound of the range to be iterated. Only entries where the key is less than (or equal to) this option will be included in the range. When `reverse` is true the order will be reversed, but the entries iterated will be the same.\n- `reverse` (boolean, default: `false`): iterate entries in reverse order. Beware that a reverse seek can be slower than a forward seek.\n- `limit` (number, default: `Infinity`): limit the number of entries yielded. This number represents a _maximum_ number of entries and will not be reached if the end of the range is reached first. A value of `Infinity` or `-1` means there is no limit. When `reverse` is true the entries with the highest keys will be returned instead of the lowest keys.\n\nThe `gte` and `lte` range options take precedence over `gt` and `lt` respectively. If no range options are provided, the iterator will visit all entries of the database, starting at the lowest key and ending at the highest key (unless `reverse` is true). In addition to range options, the `options` object may contain:\n\n- `keys` (boolean, default: `true`): whether to return the key of each entry. If set to `false`, the iterator will yield keys that are `undefined`. Prefer to use `db.keys()` instead.\n- `values` (boolean, default: `true`): whether to return the value of each entry. If set to `false`, the iterator will yield values that are `undefined`. Prefer to use `db.values()` instead.\n- `keyEncoding`: custom key encoding for this iterator, used to encode range options, to encode `seek()` targets and to decode keys.\n- `valueEncoding`: custom value encoding for this iterator, used to decode values.\n- `fillCache` (boolean, default: `false`): if set to `true`, LevelDB will fill its in-memory [LRU](http://en.wikipedia.org/wiki/Least_Recently_Used) cache with data that was read.\n- `highWaterMarkBytes` (number, default: `16 * 1024`): limit the amount of data that the iterator will hold in memory. Explained below.\n\n#### About high water\n\nWhile [`iterator.nextv(size)`](#iteratornextvsize-options-callback) is reading entries from LevelDB into memory, it sums up the byte length of those entries. If and when that sum has exceeded `highWaterMarkBytes`, reading will stop. If `nextv(2)` would normally yield two entries but the first entry is too large, then only one entry will be yielded. More `nextv(size)` calls must then be made to get the remaining entries.\n\nIf memory usage is less of a concern, increasing `highWaterMarkBytes` can increase the throughput of `nextv(size)`. If set to `0` then `nextv(size)` will never yield more than one entry, as `highWaterMarkBytes` will be exceeded on each call. It can not be set to `Infinity`. On key- and value iterators (see below) it applies to the byte length of keys or values respectively, rather than the combined byte length of keys _and_ values.\n\nOptimal performance can be achieved by setting `highWaterMarkBytes` to at least `size` multiplied by the expected byte length of an entry, ensuring that `size` is always met. In other words, that `nextv(size)` will not stop reading before `size` amount of entries have been read into memory. If the iterator is wrapped in a [Node.js stream](https://github.com/Level/read-stream) or [Web Stream](https://github.com/Level/web-stream) then the `size` parameter is dictated by the stream's `highWaterMark` option. For example:\n\n```js\nconst { EntryStream } = require('level-read-stream')\n\n// If an entry is 50 bytes on average\nconst stream = new EntryStream(db, {\n  highWaterMark: 1000,\n  highWaterMarkBytes: 1000 * 50\n})\n```\n\nSide note: the \"watermark\" analogy makes more sense in Node.js streams because its internal `highWaterMark` can grow, indicating the highest that the \"water\" has been. In a `classic-level` iterator however, `highWaterMarkBytes` is fixed once set. Getting exceeded does not change it.\n\nThe `highWaterMarkBytes` option is also applied to an internal cache that `classic-level` employs for [`next()`](#iteratornextcallback) and [`for await...of`](#for-awaitof-iterator). When `next()` is called, that cache is populated with at most 1000 entries, or less than that if `highWaterMarkBytes` is exceeded by the total byte length of entries. To avoid reading too eagerly, the cache is not populated on the first `next()` call, or the first `next()` call after a `seek()`. Only on subsequent `next()` calls.\n\n### `keyIterator = db.keys([options])`\n\nCreate a [key iterator](#keyiterator), having the same interface as `db.iterator()` except that it yields keys instead of entries. If only keys are needed, using `db.keys()` may increase performance because values won't have to fetched, copied or decoded. Options are the same as for `db.iterator()` except that `db.keys()` does not take `keys`, `values` and `valueEncoding` options.\n\n```js\n// Iterate lazily\nfor await (const key of db.keys({ gt: 'a' })) {\n  console.log(key)\n}\n\n// Get all at once. Setting a limit is recommended.\nconst keys = await db.keys({ gt: 'a', limit: 10 }).all()\n```\n\n### `valueIterator = db.values([options])`\n\nCreate a [value iterator](#valueiterator), having the same interface as `db.iterator()` except that it yields values instead of entries. If only values are needed, using `db.values()` may increase performance because keys won't have to fetched, copied or decoded. Options are the same as for `db.iterator()` except that `db.values()` does not take `keys` and `values` options. Note that it _does_ take a `keyEncoding` option, relevant for the encoding of range options.\n\n```js\n// Iterate lazily\nfor await (const value of db.values({ gt: 'a' })) {\n  console.log(value)\n}\n\n// Get all at once. Setting a limit is recommended.\nconst values = await db.values({ gt: 'a', limit: 10 }).all()\n```\n\n### `db.clear([options][, callback])`\n\nDelete all entries or a range. Not guaranteed to be atomic. Accepts the following options (with the same rules as on iterators):\n\n- `gt` (greater than) or `gte` (greater than or equal): define the lower bound of the range to be deleted. Only entries where the key is greater than (or equal to) this option will be included in the range. When `reverse` is true the order will be reversed, but the entries deleted will be the same.\n- `lt` (less than) or `lte` (less than or equal): define the higher bound of the range to be deleted. Only entries where the key is less than (or equal to) this option will be included in the range. When `reverse` is true the order will be reversed, but the entries deleted will be the same.\n- `reverse` (boolean, default: `false`): delete entries in reverse order. Only effective in combination with `limit`, to delete the last N entries.\n- `limit` (number, default: `Infinity`): limit the number of entries to be deleted. This number represents a _maximum_ number of entries and will not be reached if the end of the range is reached first. A value of `Infinity` or `-1` means there is no limit. When `reverse` is true the entries with the highest keys will be deleted instead of the lowest keys.\n- `keyEncoding`: custom key encoding for this operation, used to encode range options.\n\nThe `gte` and `lte` range options take precedence over `gt` and `lt` respectively. If no options are provided, all entries will be deleted. The `callback` function will be called with no arguments if the operation was successful or with an error if it failed. If no callback is provided, a promise is returned.\n\n### `sublevel = db.sublevel(name[, options])`\n\nCreate a [sublevel](#sublevel) that has the same interface as `db` (except for additional `classic-level` methods like `db.approximateSize()`) and prefixes the keys of operations before passing them on to `db`. The `name` argument is required and must be a string.\n\n```js\nconst example = db.sublevel('example')\n\nawait example.put('hello', 'world')\nawait db.put('a', '1')\n\n// Prints ['hello', 'world']\nfor await (const [key, value] of example.iterator()) {\n  console.log([key, value])\n}\n```\n\nSublevels effectively separate a database into sections. Think SQL tables, but evented, ranged and realtime! Each sublevel is an `AbstractLevel` instance with its own keyspace, [events](https://github.com/Level/abstract-level#events) and [encodings](https://github.com/Level/abstract-level#encodings). For example, it's possible to have one sublevel with `'buffer'` keys and another with `'utf8'` keys. The same goes for values. Like so:\n\n```js\ndb.sublevel('one', { valueEncoding: 'json' })\ndb.sublevel('two', { keyEncoding: 'buffer' })\n```\n\nAn own keyspace means that `sublevel.iterator()` only includes entries of that sublevel, `sublevel.clear()` will only delete entries of that sublevel, and so forth. Range options get prefixed too.\n\nFully qualified keys (as seen from the parent database) take the form of `prefix + key` where `prefix` is `separator + name + separator`. If `name` is empty, the effective prefix is two separators. Sublevels can be nested: if `db` is itself a sublevel then the effective prefix is a combined prefix, e.g. `'!one!!two!'`. Note that a parent database will see its own keys as well as keys of any nested sublevels:\n\n```js\n// Prints ['!example!hello', 'world'] and ['a', '1']\nfor await (const [key, value] of db.iterator()) {\n  console.log([key, value])\n}\n```\n\n> :pushpin: The key structure is equal to that of [`subleveldown`](https://github.com/Level/subleveldown) which offered sublevels before they were built-in to `abstract-level` and thus `classic-level`. This means that an `classic-level` sublevel can read sublevels previously created with (and populated by) `subleveldown`.\n\nInternally, sublevels operate on keys that are either a string, Buffer or Uint8Array, depending on choice of encoding. Which is to say: binary keys are fully supported. The `name` must however always be a string and can only contain ASCII characters.\n\nThe optional `options` object may contain:\n\n- `separator` (string, default: `'!'`): Character for separating sublevel names from user keys and each other. Must sort before characters used in `name`. An error will be thrown if that's not the case.\n- `keyEncoding` (string or object, default `'utf8'`): encoding to use for keys\n- `valueEncoding` (string or object, default `'utf8'`): encoding to use for values.\n\nThe `keyEncoding` and `valueEncoding` options are forwarded to the `AbstractLevel` constructor and work the same, as if a new, separate database was created. They default to `'utf8'` regardless of the encodings configured on `db`. Other options are forwarded too but `classic-level` has no relevant options at the time of writing. For example, setting the `createIfMissing` option will have no effect. Why is that?\n\nLike regular databases, sublevels open themselves but they do not affect the state of the parent database. This means a sublevel can be individually closed and (re)opened. If the sublevel is created while the parent database is opening, it will wait for that to finish. If the parent database is closed, then opening the sublevel will fail and subsequent operations on the sublevel will yield errors with code [`LEVEL_DATABASE_NOT_OPEN`](https://github.com/Level/abstract-level#errors).\n\n### `db.approximateSize(start, end[, options][, callback])`\n\nGet the approximate number of bytes of file system space used by the range `[start..end)`. The result might not include recently written data. The optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding for this operation, used to encode `start` and `end`.\n\nThe `callback` function will be called with a single error argument if the operation failed. If successful the first argument will be `null` and the second argument will be the approximate size as a number. If no callback is provided, a promise is returned. This method is an additional method that is not part of the [`abstract-level`](https://github.com/Level/abstract-level) interface.\n\n### `db.compactRange(start, end[, options][, callback])`\n\nManually trigger a database compaction in the range `[start..end]`. The optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding for this operation, used to encode `start` and `end`.\n\nThe `callback` function will be called with no arguments if the operation was successful or with an error if it failed. If no callback is provided, a promise is returned. This method is an additional method that is not part of the [`abstract-level`](https://github.com/Level/abstract-level) interface.\n\n### `db.getProperty(property)`\n\nGet internal details from LevelDB. When issued with a valid `property` string, a string value is returned synchronously. Valid properties are:\n\n- `leveldb.num-files-at-levelN`: return the number of files at level _N_, where N is an integer representing a valid level (e.g. \"0\").\n- `leveldb.stats`: returns a multi-line string describing statistics about LevelDB's internal operation.\n- `leveldb.sstables`: returns a multi-line string describing all of the _sstables_ that make up contents of the current database.\n\nThis method is an additional method that is not part of the [`abstract-level`](https://github.com/Level/abstract-level) interface.\n\n### `chainedBatch`\n\n#### `chainedBatch.put(key, value[, options])`\n\nQueue a `put` operation on this batch, not committed until `write()` is called. This will throw a [`LEVEL_INVALID_KEY`](https://github.com/Level/abstract-level#errors) or [`LEVEL_INVALID_VALUE`](https://github.com/Level/abstract-level#errors) error if `key` or `value` is invalid. The optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding for this operation, used to encode the `key`.\n- `valueEncoding`: custom value encoding for this operation, used to encode the `value`.\n- `sublevel` (sublevel instance): act as though the `put` operation is performed on the given sublevel, to similar effect as `sublevel.batch().put(key, value)`. This allows atomically committing data to multiple sublevels. The `key` will be prefixed with the `prefix` of the sublevel, and the `key` and `value` will be encoded by the sublevel (using the default encodings of the sublevel unless `keyEncoding` and / or `valueEncoding` are provided).\n\n#### `chainedBatch.del(key[, options])`\n\nQueue a `del` operation on this batch, not committed until `write()` is called. This will throw a [`LEVEL_INVALID_KEY`](https://github.com/Level/abstract-level#errors) error if `key` is invalid. The optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding for this operation, used to encode the `key`.\n- `sublevel` (sublevel instance): act as though the `del` operation is performed on the given sublevel, to similar effect as `sublevel.batch().del(key)`. This allows atomically committing data to multiple sublevels. The `key` will be prefixed with the `prefix` of the sublevel, and the `key` will be encoded by the sublevel (using the default key encoding of the sublevel unless `keyEncoding` is provided).\n\n#### `chainedBatch.clear()`\n\nClear all queued operations on this batch.\n\n#### `chainedBatch.write([options][, callback])`\n\nCommit the queued operations for this batch. All operations will be written atomically, that is, they will either all succeed or fail with no partial commits.\n\nThe optional `options` object may contain:\n\n- `sync` (boolean, default: `false`): same as described for [`db.put()`](#dbputkey-value-options-callback).\n\nNote that `write()` does not take encoding options. Those can only be set on `put()` and `del()` because `classic-level` synchronously forwards such calls to LevelDB and thus need keys and values to be encoded at that point.\n\nThe `callback` function will be called with no arguments if the batch was successful or with an error if it failed. If no callback is provided, a promise is returned.\n\nAfter `write()` or `close()` has been called, no further operations are allowed.\n\n#### `chainedBatch.close([callback])`\n\nFree up underlying resources. This should be done even if the chained batch has zero queued operations. Automatically called by `write()` so normally not necessary to call, unless the intent is to discard a chained batch without committing it. The `callback` function will be called with no arguments. If no callback is provided, a promise is returned. Closing the batch is an idempotent operation, such that calling `close()` more than once is allowed and makes no difference.\n\n#### `chainedBatch.length`\n\nThe number of queued operations on the current batch.\n\n#### `chainedBatch.db`\n\nA reference to the database that created this chained batch.\n\n### `iterator`\n\nAn iterator allows one to lazily read a range of entries stored in the database. The entries will be sorted by keys in [lexicographic order](https://en.wikipedia.org/wiki/Lexicographic_order) (in other words: byte order) which in short means key `'a'` comes before `'b'` and key `'10'` comes before `'2'`.\n\nAn iterator reads from a snapshot of the database, created at the time `db.iterator()` was called. This means the iterator will not see the data of simultaneous write operations.\n\nIterators can be consumed with [`for await...of`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of) and `iterator.all()`, or by manually calling `iterator.next()` or `nextv()` in succession. In the latter case, `iterator.close()` must always be called. In contrast, finishing, throwing, breaking or returning from a `for await...of` loop automatically calls `iterator.close()`, as does `iterator.all()`.\n\nAn iterator reaches its natural end in the following situations:\n\n- The end of the database has been reached\n- The end of the range has been reached\n- The last `iterator.seek()` was out of range.\n\nAn iterator keeps track of calls that are in progress. It doesn't allow concurrent `next()`, `nextv()` or `all()` calls (including a combination thereof) and will throw an error with code [`LEVEL_ITERATOR_BUSY`](https://github.com/Level/abstract-level#errors) if that happens:\n\n```js\n// Not awaited and no callback provided\niterator.next()\n\ntry {\n  // Which means next() is still in progress here\n  iterator.all()\n} catch (err) {\n  console.log(err.code) // 'LEVEL_ITERATOR_BUSY'\n}\n```\n\n#### `for await...of iterator`\n\nYields entries, which are arrays containing a `key` and `value`. The type of `key` and `value` depends on the options passed to `db.iterator()`.\n\n```js\ntry {\n  for await (const [key, value] of db.iterator()) {\n    console.log(key)\n  }\n} catch (err) {\n  console.error(err)\n}\n```\n\n#### `iterator.next([callback])`\n\nAdvance to the next entry and yield that entry. If an error occurs, the `callback` function will be called with an error. Otherwise, the `callback` receives `null`, a `key` and a `value`. The type of `key` and `value` depends on the options passed to `db.iterator()`. If the iterator has reached its natural end, both `key` and `value` will be `undefined`.\n\nIf no callback is provided, a promise is returned for either an array (containing a `key` and `value`) or `undefined` if the iterator reached its natural end.\n\n**Note:** `iterator.close()` must always be called once there's no intention to call `next()` or `nextv()` again. Even if such calls yielded an error and even if the iterator reached its natural end. Not closing the iterator will result in memory leaks and may also affect performance of other operations if many iterators are unclosed and each is holding a snapshot of the database.\n\n#### `iterator.nextv(size[, options][, callback])`\n\nAdvance repeatedly and get at most `size` amount of entries in a single call. Can be faster than repeated `next()` calls. The `size` argument must be an integer and has a soft minimum of 1. There are no `options` currently.\n\nIf an error occurs, the `callback` function will be called with an error. Otherwise, the `callback` receives `null` and an array of entries, where each entry is an array containing a key and value. The natural end of the iterator will be signaled by yielding an empty array. If no callback is provided, a promise is returned.\n\n```js\nconst iterator = db.iterator()\n\nwhile (true) {\n  const entries = await iterator.nextv(100)\n\n  if (entries.length === 0) {\n    break\n  }\n\n  for (const [key, value] of entries) {\n    // ..\n  }\n}\n\nawait iterator.close()\n```\n\n#### `iterator.all([options][, callback])`\n\nAdvance repeatedly and get all (remaining) entries as an array, automatically closing the iterator. Assumes that those entries fit in memory. If that's not the case, instead use `next()`, `nextv()` or `for await...of`. There are no `options` currently. If an error occurs, the `callback` function will be called with an error. Otherwise, the `callback` receives `null` and an array of entries, where each entry is an array containing a key and value. If no callback is provided, a promise is returned.\n\n```js\nconst entries = await db.iterator({ limit: 100 }).all()\n\nfor (const [key, value] of entries) {\n  // ..\n}\n```\n\n#### `iterator.seek(target[, options])`\n\nSeek to the key closest to `target`. Subsequent calls to `iterator.next()`, `nextv()` or `all()` (including implicit calls in a `for await...of` loop) will yield entries with keys equal to or larger than `target`, or equal to or smaller than `target` if the `reverse` option passed to `db.iterator()` was true.\n\nThe optional `options` object may contain:\n\n- `keyEncoding`: custom key encoding, used to encode the `target`. By default the `keyEncoding` option of the iterator is used or (if that wasn't set) the `keyEncoding` of the database.\n\nIf range options like `gt` were passed to `db.iterator()` and `target` does not fall within that range, the iterator will reach its natural end.\n\n#### `iterator.close([callback])`\n\nFree up underlying resources. The `callback` function will be called with no arguments. If no callback is provided, a promise is returned. Closing the iterator is an idempotent operation, such that calling `close()` more than once is allowed and makes no difference.\n\nIf a `next()` ,`nextv()` or `all()` call is in progress, closing will wait for that to finish. After `close()` has been called, further calls to `next()` ,`nextv()` or `all()` will yield an error with code [`LEVEL_ITERATOR_NOT_OPEN`](https://github.com/Level/abstract-level#errors).\n\n#### `iterator.db`\n\nA reference to the database that created this iterator.\n\n#### `iterator.count`\n\nRead-only getter that indicates how many keys have been yielded so far (by any method) excluding calls that errored or yielded `undefined`.\n\n#### `iterator.limit`\n\nRead-only getter that reflects the `limit` that was set in options. Greater than or equal to zero. Equals `Infinity` if no limit, which allows for easy math:\n\n```js\nconst hasMore = iterator.count < iterator.limit\nconst remaining = iterator.limit - iterator.count\n```\n\n### `keyIterator`\n\nA key iterator has the same interface as `iterator` except that its methods yield keys instead of entries. For the `keyIterator.next(callback)` method, this means that the `callback` will receive two arguments (an error and key) instead of three. Usage is otherwise the same.\n\n### `valueIterator`\n\nA value iterator has the same interface as `iterator` except that its methods yield values instead of entries. For the `valueIterator.next(callback)` method, this means that the `callback` will receive two arguments (an error and value) instead of three. Usage is otherwise the same.\n\n### `sublevel`\n\nA sublevel is an instance of the `AbstractSublevel` class (as found in [`abstract-level`](https://github.com/Level/abstract-level)) which extends `AbstractLevel` and thus has the same API as documented above, except for additional `classic-level` methods like `db.approximateSize()`. Sublevels have a few additional properties.\n\n#### `sublevel.prefix`\n\nPrefix of the sublevel. A read-only string property.\n\n```js\nconst example = db.sublevel('example')\nconst nested = example.sublevel('nested')\n\nconsole.log(example.prefix) // '!example!'\nconsole.log(nested.prefix) // '!example!!nested!'\n```\n\n#### `sublevel.db`\n\nParent database. A read-only property.\n\n```js\nconst example = db.sublevel('example')\nconst nested = example.sublevel('nested')\n\nconsole.log(example.db === db) // true\nconsole.log(nested.db === db) // true\n```\n\n### `ClassicLevel.destroy(location[, callback])`\n\nCompletely remove an existing LevelDB database directory. You can use this method in place of a full directory removal if you want to be sure to only remove LevelDB-related files. If the directory only contains LevelDB files, the directory itself will be removed as well. If there are additional, non-LevelDB files in the directory, those files and the directory will be left alone.\n\nThe `callback` function will be called when the destroy operation is complete, with a possible error argument. If no callback is provided, a promise is returned. This method is an additional method that is not part of the [`abstract-level`](https://github.com/Level/abstract-level) interface.\n\nBefore calling `destroy()`, close a database if it's using the same `location`:\n\n```js\nconst db = new ClassicLevel('./db')\nawait db.close()\nawait ClassicLevel.destroy('./db')\n```\n\n### `ClassicLevel.repair(location[, callback])`\n\nAttempt a restoration of a damaged database. It can also be used to perform a compaction of the LevelDB log into table files. From LevelDB documentation:\n\n> If a DB cannot be opened, you may attempt to call this method to resurrect as much of the contents of the database as possible. Some data may be lost, so be careful when calling this function on a database that contains important information.\n\nThe `callback` function will be called when the repair operation is complete, with a possible error argument. If no callback is provided, a promise is returned. This method is an additional method that is not part of the [`abstract-level`](https://github.com/Level/abstract-level) interface.\n\nYou will find information on the repair operation in the `LOG` file inside the database directory.\n\nBefore calling `repair()`, close a database if it's using the same `location`.\n\n## Development\n\n### Getting Started\n\nThis repository uses git submodules. Clone it recursively:\n\n```bash\ngit clone --recurse-submodules https://github.com/Level/classic-level.git\n```\n\nAlternatively, initialize submodules inside the working tree:\n\n```bash\ncd classic-level\ngit submodule update --init --recursive\n```\n\n### Contributing\n\n[`Level/classic-level`](https://github.com/Level/classic-level) is an **OPEN Open Source Project**. This means that:\n\n> Individuals making significant and valuable contributions are given commit-access to the project to contribute as they see fit. This project is more like an open wiki than a standard guarded open source project.\n\nSee the [Contribution Guide](https://github.com/Level/community/blob/master/CONTRIBUTING.md) for more details.\n\n### Publishing\n\n1. Increment the version: `npm version ..`\n2. Push to GitHub: `git push --follow-tags`\n3. Wait for CI to complete\n4. Download prebuilds into `./prebuilds`: `npm run download-prebuilds`\n5. Optionally verify loading a prebuild: `npm run test-prebuild`\n6. Optionally verify which files npm will include: `canadian-pub`\n7. Finally: `npm publish`\n\n## Donate\n\nSupport us with a monthly donation on [Open Collective](https://opencollective.com/level) and help us continue our work.\n\n## License\n\n[MIT](LICENSE)\n\n[level-badge]: https://leveljs.org/img/badge.svg\n",
    "licenseText": "MIT License\n\nCopyright (c) 2012 Rod Vagg and the contributors to classic-level and leveldown.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.npmjs.org/classic-level/-/classic-level-1.3.0.tgz",
    "type": "tarball",
    "reference": "https://registry.npmjs.org/classic-level/-/classic-level-1.3.0.tgz",
    "hash": "",
    "integrity": "sha512-iwFAJQYtqRTRM0F6L8h4JCt00ZSGdOyqh7yVrhhjrOpFhmBjNlRUey64MCiyo6UmQHMJ+No3c81nujPv+n9yrg==",
    "registry": "npm",
    "packageName": "classic-level",
    "cacheIntegrity": "sha512-iwFAJQYtqRTRM0F6L8h4JCt00ZSGdOyqh7yVrhhjrOpFhmBjNlRUey64MCiyo6UmQHMJ+No3c81nujPv+n9yrg== sha1-XjZoDgHcaycXdcCT8hUIRMXt1cg="
  },
  "registry": "npm",
  "hash": "8b014025062da914d133417a2fc878242b74d1948674ecaa87bc95ae1863acea458660633654547b2eb83028b2a3a526407309f8da3773cd67ba33effa7f72ae"
}